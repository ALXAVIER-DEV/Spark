{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Aula 4 - Introdução aos RDDs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALXAVIER-DEV/Spark/blob/master/Aula_4_Introdu%C3%A7%C3%A3o_aos_RDDs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq8U3BtmhtRx"
      },
      "source": [
        "\n",
        "# **Running Pyspark in Colab**\n",
        "\n",
        "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 3.0.1 with hadoop 2.7 and Java 8. The tools installation can be carried out inside the Jupyter Notebook of the Colab. One important note is that if you are new in Spark, it is better to avoid Spark 2.4.0 version since some people have already complained about its compatibility issue with python. \n",
        "Follow the steps to install the dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILheUROOhprv"
      },
      "source": [
        "Now that you installed Spark and Java in Colab, it is time to set the environment path which enables you to run Pyspark in your Colab environment. Set the location of Java and Spark by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1b8k_OVf2QF"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwrqMk3HiMiE"
      },
      "source": [
        "Run a local spark session to test your installation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Uz1NL4gHFx"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14pXEN-M0hfV"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l57w6j1HrcGr"
      },
      "source": [
        "# Reading a CSV from google drive\n",
        "\n",
        "Utilizando o Google Colab, é possível importar os datasets diretamente do Google Drive, sem ter que realizar o upload manual dos mesmos para a instância colab manualmente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyIlwwr7xENz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4LB-SAxzAFr"
      },
      "source": [
        "spark.read\\\n",
        "  .option(\"inferSchema\", \"true\") \\\n",
        "  .option(\"header\", \"true\") \\\n",
        "  .option(\"delimiter\", \",\") \\\n",
        "  .csv(\"drive/My\\ Drive/My\\ Professional\\ Carrer/Spark\\ course/virtual_classroom/colab_test/test.csv\") \\\n",
        "  .show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mtNk9_bKiAF"
      },
      "source": [
        "# Introdução aos RDDs\n",
        "Nessa aula veremos o que são os RDDs ou Resilient Distributed Datasets e como interagir com algumas operações básicas sobre os mesmos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRmRSQQ4KiAF"
      },
      "source": [
        "### RDD\n",
        "RDD ou Resilient Distributed Datasets são estruturas distribuídas e imutáveis de objetos Python, Scala, Java ou qualquer que seja a linguagem que o usuário esteja operando os RDDs. Ao contrário dos Dataframes que são estruturados no conceito de Row com um schema conhecido, os RDDs são genéricos deixando a cargo do programador o seu uso e a sua estruturação\n",
        "\n",
        "### Low-level APIs\n",
        "São APIs baixo nível fornecidas pelo Spark para manipular as estruturas elementares do Spark: os **RDDs**, **Shared Variables** e **Accumulators**. Normalmente o usuário opta por usar as Low-level APIs em 3 situações:\n",
        "- Quando é necessário ter o controle explícito de como o dado é distribuído ao longo do cluster\n",
        "- Manter código legado escrito usando RDDs\n",
        "- Acessar variáveis compartilhadas no cluster como um todo\n",
        "\n",
        "Mesmo que você seja avançado em programação com RDDs, é recomendado que você siga utilizando as APIs High-level, a menos que se depare com uma das 3 situações acima. Ao utilizar os RDDs, assume-se que todo o controle está na mão do usuário e este pode não saber ao certo o que está fazendo e danificar a performance da aplicação.\n",
        "\n",
        "É importante ressaltar que a API High-level Dataframe é inteiramente baseada nos RDDs, ou seja, toda transformação realizada em cima dos Dataframes, se torna uma transformação primitiva em RDD e entender como funciona essas APIs pode fazer a diferença na construção de aplicações com mais performance e robustez.\n",
        "\n",
        "### Spark Context\n",
        "É o ponto de entrada para se trabalhar com as Low-level APIs. Está para os RDDs assim como o Spark Session está para os Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0N9469EKiAG"
      },
      "source": [
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr4Lo-z4KiAK"
      },
      "source": [
        "### Criando RDDs\n",
        "Ao criar um RDD, é possível criá-lo de 3 formas: \n",
        "- a partir de coleções locais em Python\n",
        "- a partir de data sources primitivas\n",
        "- a partir de Dataframes\n",
        "\n",
        "##### Utilizando coleções locais\n",
        "Ao utilizar coleções locais, temos o comando `sc.parallelize()` que recebe como parâmetro a **coleção** e o número de **partições**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fYa-QzRKiAK"
      },
      "source": [
        "text = \"Spark The Definitive Guide : Big Data Processing Made Simple\"\n",
        "collection = text.split(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvbTnQihD7m2",
        "outputId": "9a9ab0e2-baa4-4c51-93f8-f461bd7d9f64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(collection)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4y0xPmxKiAM",
        "outputId": "958ba6da-b1db-4a66-9133-b3ace38c1e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd_words = sc.parallelize(collection, 2)\n",
        "rdd_words.setName(\"myWords\")\n",
        "rdd_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "myWords ParallelCollectionRDD[5] at readRDDFromFile at PythonRDD.scala:262"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzBgFdmEKiAP",
        "outputId": "af147f52-7039-4ad7-e5ff-772ca4c4301a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd_words.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Spark',\n",
              " 'The',\n",
              " 'Definitive',\n",
              " 'Guide',\n",
              " ':',\n",
              " 'Big',\n",
              " 'Data',\n",
              " 'Processing',\n",
              " 'Made',\n",
              " 'Simple']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3jKiHZGAtK",
        "outputId": "a5fc1d60-ddb9-4ce8-9cc7-5ad04d5eca0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_dict = [{\n",
        "    \"nome\":\"Jose\",\n",
        "    \"idade\": 52,\n",
        "    \"profissao\": \"Advogado\"\n",
        "},{\n",
        "    \"nome\":\"Maria\",\n",
        "    \"idade\": 35,\n",
        "    \"profissao\": \"Médico\",\n",
        "    \"sexo\": \"feminino\"\n",
        "},{\n",
        "    \"nome\":\"Pedro\",\n",
        "    \"idade\": 25,\n",
        "    \"profissao\": \"Estudante\"\n",
        "},\n",
        "print,\n",
        "True]\n",
        "\n",
        "data_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'idade': 52, 'nome': 'Jose', 'profissao': 'Advogado'},\n",
              " {'idade': 35, 'nome': 'Maria', 'profissao': 'Médico', 'sexo': 'feminino'},\n",
              " {'idade': 25, 'nome': 'Pedro', 'profissao': 'Estudante'},\n",
              " <function print>,\n",
              " True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srEr3Aw_GCqK",
        "outputId": "b4d05730-50e1-4bad-bec9-35e8324b61c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd_dict = sc.parallelize(data_dict, 2)\n",
        "rdd_dict.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'idade': 52, 'nome': 'Jose', 'profissao': 'Advogado'},\n",
              " {'idade': 35, 'nome': 'Maria', 'profissao': 'Médico', 'sexo': 'feminino'},\n",
              " {'idade': 25, 'nome': 'Pedro', 'profissao': 'Estudante'},\n",
              " <function print>,\n",
              " True]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBF8hF56KiAR"
      },
      "source": [
        "##### Utilizando arquivos como data source\n",
        "Ao utilizar arquivos de texto, cada linha do arquivo será uma linha do RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmwaz-kOKiAS",
        "outputId": "c80fbb55-f063-4492-e43d-5d5e5cd5d73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_dir = \"vgsales.csv\"\n",
        "\n",
        "rdd = sc.textFile(data_dir)\n",
        "rdd.setName(\"vgsales_csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vgsales_csv MapPartitionsRDD[15] at textFile at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS5SVUtFKiAV",
        "outputId": "38c67a1c-2b56-4405-ff84-eca8459ff154",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rank,Name,Platform,Year,Genre,Publisher,NA_Sales,EU_Sales,JP_Sales,Other_Sales,Global_Sales',\n",
              " '1,Wii Sports,Wii,2006,Sports,Nintendo,41.49,29.02,3.77,8.46,82.74',\n",
              " '2,Super Mario Bros.,NES,1985,Platform,Nintendo,29.08,3.58,6.81,0.77,40.24',\n",
              " '3,Mario Kart Wii,Wii,2008,Racing,Nintendo,15.85,12.88,3.79,3.31,35.82',\n",
              " '4,Wii Sports Resort,Wii,2009,Sports,Nintendo,15.75,11.01,3.28,2.96,33',\n",
              " '5,Pokemon Red/Pokemon Blue,GB,1996,Role-Playing,Nintendo,11.27,8.89,10.22,1,31.37',\n",
              " '6,Tetris,GB,1989,Puzzle,Nintendo,23.2,2.26,4.22,0.58,30.26',\n",
              " '7,New Super Mario Bros.,DS,2006,Platform,Nintendo,11.38,9.23,6.5,2.9,30.01',\n",
              " '8,Wii Play,Wii,2006,Misc,Nintendo,14.03,9.2,2.93,2.85,29.02',\n",
              " '9,New Super Mario Bros. Wii,Wii,2009,Platform,Nintendo,14.59,7.06,4.7,2.26,28.62']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK1OiWX7KiAX"
      },
      "source": [
        "### Interoperabilidade entre Dataframes e RDDs\n",
        "As APIs do Spark fornecem métodos para realizar a conversão de Dataframes em RDDs e vice versa. Para isso, temos dois métodos importantes: `rdd` e `toDF()`\n",
        "\n",
        "##### Convertendo um Dataframe para um RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMSK3O0WKiAY"
      },
      "source": [
        "df = spark.read.load(data_dir, format=\"csv\", inferSchema=\"true\", header=\"true\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eLw0KeGKiAa",
        "outputId": "a3476395-78ea-41ba-d9c6-1f13f3b59be1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.rdd.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Rank=1, Name='Wii Sports', Platform='Wii', Year='2006', Genre='Sports', Publisher='Nintendo', NA_Sales=41.49, EU_Sales=29.02, JP_Sales=3.77, Other_Sales=8.46, Global_Sales=82.74),\n",
              " Row(Rank=2, Name='Super Mario Bros.', Platform='NES', Year='1985', Genre='Platform', Publisher='Nintendo', NA_Sales=29.08, EU_Sales=3.58, JP_Sales=6.81, Other_Sales=0.77, Global_Sales=40.24),\n",
              " Row(Rank=3, Name='Mario Kart Wii', Platform='Wii', Year='2008', Genre='Racing', Publisher='Nintendo', NA_Sales=15.85, EU_Sales=12.88, JP_Sales=3.79, Other_Sales=3.31, Global_Sales=35.82),\n",
              " Row(Rank=4, Name='Wii Sports Resort', Platform='Wii', Year='2009', Genre='Sports', Publisher='Nintendo', NA_Sales=15.75, EU_Sales=11.01, JP_Sales=3.28, Other_Sales=2.96, Global_Sales=33.0),\n",
              " Row(Rank=5, Name='Pokemon Red/Pokemon Blue', Platform='GB', Year='1996', Genre='Role-Playing', Publisher='Nintendo', NA_Sales=11.27, EU_Sales=8.89, JP_Sales=10.22, Other_Sales=1.0, Global_Sales=31.37)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1t9Gu5uKiAc"
      },
      "source": [
        "##### Convertendo um RDD para um Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7BJzbdzKiAc",
        "outputId": "e24ab8d9-16dc-4ca9-d829-77dd37446d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd = sc.textFile(data_dir)\n",
        "rdd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vgsales.csv MapPartitionsRDD[36] at textFile at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leZIIBk2KiAe",
        "outputId": "6765fe8f-1d05-47ca-afad-9e3d0187ea54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd \\\n",
        "    .map(lambda x: (x,)) \\\n",
        "    .toDF() \\\n",
        "    .show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                  _1|\n",
            "+--------------------+\n",
            "|Rank,Name,Platfor...|\n",
            "|1,Wii Sports,Wii,...|\n",
            "|2,Super Mario Bro...|\n",
            "|3,Mario Kart Wii,...|\n",
            "|4,Wii Sports Reso...|\n",
            "|5,Pokemon Red/Pok...|\n",
            "|6,Tetris,GB,1989,...|\n",
            "|7,New Super Mario...|\n",
            "|8,Wii Play,Wii,20...|\n",
            "|9,New Super Mario...|\n",
            "|10,Duck Hunt,NES,...|\n",
            "|11,Nintendogs,DS,...|\n",
            "|12,Mario Kart DS,...|\n",
            "|13,Pokemon Gold/P...|\n",
            "|14,Wii Fit,Wii,20...|\n",
            "|15,Wii Fit Plus,W...|\n",
            "|16,Kinect Adventu...|\n",
            "|17,Grand Theft Au...|\n",
            "|18,Grand Theft Au...|\n",
            "|19,Super Mario Wo...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMslBlTXMD_A",
        "outputId": "15d583b6-6c61-45f0-9dda-23cd8782b0d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_dict = [{\n",
        "    \"nome\":\"Jose\",\n",
        "    \"idade\": 52,\n",
        "    \"profissao\": \"Advogado\",\n",
        "    \"sexo\": 1\n",
        "},{\n",
        "    \"nome\":\"Maria\",\n",
        "    \"idade\": 35,\n",
        "    \"profissao\": \"Médico\",\n",
        "    \"sexo\": \"feminino\"\n",
        "},{\n",
        "    \"nome\":\"Pedro\",\n",
        "    \"idade\": 25,\n",
        "    \"profissao\": \"Estudante\"\n",
        "}]\n",
        "\n",
        "data_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'idade': 52, 'nome': 'Jose', 'profissao': 'Advogado', 'sexo': 1},\n",
              " {'idade': 35, 'nome': 'Maria', 'profissao': 'Médico', 'sexo': 'feminino'},\n",
              " {'idade': 25, 'nome': 'Pedro', 'profissao': 'Estudante'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXQ8_5YwKiAh",
        "outputId": "950b0e4c-767a-4dde-fef7-bcaf12391460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd = sc.parallelize(data_dict)\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'idade': 52, 'nome': 'Jose', 'profissao': 'Advogado', 'sexo': 1},\n",
              " {'idade': 35, 'nome': 'Maria', 'profissao': 'Médico', 'sexo': 'feminino'},\n",
              " {'idade': 25, 'nome': 'Pedro', 'profissao': 'Estudante'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glQI45eTMTEq",
        "outputId": "50ad592b-7ed0-4c62-9d73-54022880b18e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rdd.toDF().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py:401: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
            "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+---------+----+\n",
            "|idade| nome|profissao|sexo|\n",
            "+-----+-----+---------+----+\n",
            "|   52| Jose| Advogado|   1|\n",
            "|   35|Maria|   Médico|null|\n",
            "|   25|Pedro|Estudante|null|\n",
            "+-----+-----+---------+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPLvFV4eMqp-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}